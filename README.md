# Give_A_Sign
##Abstract :
This project presents the development and implementation of a Sign
Language Recognition System designed to bridge the communication
gap between the deaf and hearing communities. Utilizing advanced
Machine learning techniques, the system accurately interprets sign
language gestures into spoken language and text. The core of the system
It is built on YOLO V8 that has been trained on a comprehensive dataset
of sign language gestures, encompassing a wide range of signs from
American Sign Language (ASL) and Arabic language.
using the trained YOLO model. The system
Demonstrates high accuracy in recognizing both static and dynamic
signs, offering an intuitive interface for users to communicate
effectively
###Arabic model :
total number of images are 1612 of 42 class for Arabic detection and . It is also openly available on the internet. Each class contains approximately 30 image and its label[image]
#### Note : 
In the Arabic model, I created a dictionary to translate labels from English to Arabic because they are originally English, and it was created like this because the RoboFlow website does not support the Arabic language
###English model : 
total number of images are 941 of 31 class for Arabic detection and . It is also openly available on the internet. Each class contains approximately 30 image and its label ![image

